{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import axs\n",
    "import numpy as np\n",
    "from astropy.io import fits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def spark_start(project_path, metastore=None):\n",
    "    from pyspark.sql import SparkSession\n",
    "\n",
    "    warehouse_location = os.path.join(project_path, 'spark-warehouse')\n",
    "\n",
    "    local_dir = os.path.join(project_path, 'spark-tmp')\n",
    "\n",
    "    spark = ( \n",
    "            SparkSession.builder\n",
    "            .appName(\"LSD2\")\n",
    "            .config(\"spark.sql.warehouse.dir\", warehouse_location)\n",
    "            .config('spark.master', \"local[4]\")\n",
    "            .config('spark.driver.memory', '6G') # 128\n",
    "            .config('spark.local.dir', local_dir)\n",
    "            .config('spark.memory.offHeap.enabled', 'true')\n",
    "            .config('spark.memory.offHeap.size', '4G') # 256\n",
    "            .config(\"spark.sql.execution.arrow.enabled\", \"true\")\n",
    "            .config(\"spark.driver.maxResultSize\", \"6G\")\n",
    "            .config(\"spark.driver.extraJavaOptions\", f\"-Dderby.system.home={metastore}\")\n",
    "            .enableHiveSupport()\n",
    "            .getOrCreate()\n",
    "                    )   \n",
    "\n",
    "    return spark\n",
    "\n",
    "spark_session = spark_start(\"/epyc/users/ctslater\")\n",
    "\n",
    "catalog = axs.AxsCatalog(spark_session)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sesar_df = (spark_session.read.format(\"csv\").option(\"delimiter\", \",\")\n",
    "            .load(\"sesar.csv\", inferSchema=True, header=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "renamed_df = (sesar_df.withColumnRenamed(\"RAJ2000\", \"ra\")\n",
    "                      .withColumnRenamed(\"DEJ2000\", \"dec\")\n",
    "                      .withColumnRenamed(\"E(B-V)\", \"EBV\") )\n",
    "catalog.save_axs_table(renamed_df, \"sesar_rrlyrae\", calculate_zone=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3-AXS Spark",
   "language": "python",
   "name": "spark-smj"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
